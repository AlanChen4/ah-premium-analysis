{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81aea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7737f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ah_shares = pd.read_excel('ah_shares.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db123df2",
   "metadata": {},
   "source": [
    "## Download Data using YFinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce65403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_historical_data(row):\n",
    "    \"\"\"\n",
    "    Download 5y historical data and store as .csv in historical_data folder\n",
    "    \"\"\"\n",
    "    # modify symbol to match yahoo finance records\n",
    "    hk_sym = row['HK_Symbol'][1:]\n",
    "    if 'SH' in row['China_Symbol']:\n",
    "        china_sym = row['China_Symbol'].replace('SH', 'SS')\n",
    "    else:\n",
    "        china_sym = row['China_Symbol']\n",
    "    \n",
    "    # fetch data using yfinance\n",
    "    hk_ticker = yf.Ticker(hk_sym)\n",
    "    hk_historical = hk_ticker.history(period='5y', interval='1d')\n",
    "    hk_historical.to_csv(f'historical_data/{row[\"HK_Symbol\"]}.csv')\n",
    "    \n",
    "    china_ticker = yf.Ticker(china_sym)\n",
    "    china_historical = china_ticker.history(period='5y', interval='1d')\n",
    "    china_historical.to_csv(f'historical_data/{row[\"China_Symbol\"]}.csv')\n",
    "    \n",
    "    print(f\"Finished {hk_sym} : {china_sym}\")\n",
    "    \n",
    "def download_stock_info_data(row):\n",
    "    \"\"\"\n",
    "    Download stock info data and store as .json in stock_info folder\n",
    "    \"\"\"\n",
    "    # modify symbol to match yahoo finance records\n",
    "    hk_sym = row['HK_Symbol'][1:]\n",
    "    if 'SH' in row['China_Symbol']:\n",
    "        china_sym = row['China_Symbol'].replace('SH', 'SS')\n",
    "    else:\n",
    "        china_sym = row['China_Symbol']\n",
    "    \n",
    "    # fetch data using yfinance\n",
    "    hk_ticker = yf.Ticker(hk_sym)\n",
    "    hk_info = hk_ticker.info\n",
    "    \n",
    "    china_ticker = yf.Ticker(china_sym)\n",
    "    china_info = china_ticker.info\n",
    "    \n",
    "    with open(f'stock_info/{row[\"HK_Symbol\"]}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(hk_info, f)\n",
    "        \n",
    "    with open(f'stock_info/{row[\"China_Symbol\"]}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(china_info, f)\n",
    "    \n",
    "    print(f\"Finished {hk_sym} : {china_sym}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841ff587",
   "metadata": {},
   "outputs": [],
   "source": [
    "ah_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860dfc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download historical data\n",
    "# ah_shares.apply(download_historical_data, axis=1)\n",
    "\n",
    "# download stock info\n",
    "# ah_shares.apply(download_stock_info_data, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbeeba1",
   "metadata": {},
   "source": [
    "## Premium Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f6a015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median_premium_plot(df, output=[]):\n",
    "    \"\"\"\n",
    "    Returns the median A-H Premium (A Price / H Price)\n",
    "    \"\"\"\n",
    "    hk_sym = df['HK_Symbol']\n",
    "    china_sym = df['China_Symbol']\n",
    "    \n",
    "    hk_data = pd.read_csv(f'historical_data/{hk_sym}.csv', index_col=0)\n",
    "    china_data = pd.read_csv(f'historical_data/{china_sym}.csv', index_col=0)\n",
    "    \n",
    "    merged =  pd.merge(hk_data, china_data, left_index=True, right_index=True,\n",
    "                       suffixes=('_HK', '_China'))\n",
    "    \n",
    "    premium = merged['Close_China'] / merged['Close_HK']\n",
    "    premium = premium.to_frame().rename(columns={0: 'Premium'})\n",
    "    \n",
    "    output.append(premium)\n",
    "    \n",
    "    return premium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c453ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "premiums = []\n",
    "ah_shares.apply(get_median_premium_plot, axis=1, args=(premiums, ))\n",
    "all_premiums = reduce(lambda x, y: pd.merge(x, y, \n",
    "                                            on='Date', \n",
    "                                            how='outer'), premiums)\n",
    "all_premiums = all_premiums.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a0dd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "median_premium = all_premiums.median(axis=1)\n",
    "median_plot_ax = median_premium.plot(rot=20, \n",
    "                                     title=\"5y Median A-H Premium\", \n",
    "                                     figsize=(8, 4))\n",
    "median_plot_ax.set_ylim(0, 2)\n",
    "median_plot_ax.set_ylabel('A price / H Price')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e999f23e",
   "metadata": {},
   "source": [
    "### Calculate Rolling Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2889d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rolling_vol = median_premium.pct_change().rolling(60).std()*(252**0.5)\n",
    "rolling_vol_ax = rolling_vol.plot(rot=20, \n",
    "                                  title=\"Median A-H Premium Rolling Vol\", \n",
    "                                  figsize=(8, 4))\n",
    "rolling_vol_ax.set_ylim(0, 0.3)\n",
    "rolling_vol_ax.set_ylabel(\"Vol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ce37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stock info data\n",
    "def load_stock_info_data(row, output={}):\n",
    "    \"\"\"\n",
    "    Load existing stock info data for entries in the DataFrame\n",
    "    \"\"\"\n",
    "    hk_sym = row['HK_Symbol']\n",
    "    china_sym = row['China_Symbol']\n",
    "    \n",
    "    with open(f'stock_info/{hk_sym}.json') as f:\n",
    "        hk_info = json.load(f)\n",
    "        \n",
    "    with open(f'stock_info/{china_sym}.json') as f:\n",
    "        china_info = json.load(f)\n",
    "        \n",
    "    output[hk_sym] = hk_info\n",
    "    output[china_sym] = china_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_info = {}\n",
    "ah_shares.apply(load_stock_info_data, args=(stock_info, ), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c544e0",
   "metadata": {},
   "source": [
    "## ASHR | FXI Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72021b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ashr_ticker = yf.Ticker('ASHR')\n",
    "ashr_history = ashr_ticker.history(period='5y', interval='1d')\n",
    "\n",
    "fxi_ticker = yf.Ticker('FXI')\n",
    "fxi_history = fxi_ticker.history(period='5y', interval='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d638f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = (ashr_history['Close'].pct_change().cumsum()*100).plot(figsize=(8, 6),\n",
    "                                                 title='ASHR vs FXI Cumulative Returns',\n",
    "                                                 legend=True, \n",
    "                                                 label='ASHR')\n",
    "(fxi_history['Close'].pct_change().cumsum()*100).plot(legend=True, \n",
    "                                                label='FXI')\n",
    "ax.set_ylabel('Percent %')\n",
    "ax.set_ylim(-20, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98202012",
   "metadata": {},
   "outputs": [],
   "source": [
    "ashr_fxi_difference = ashr_history['Close'].pct_change().cumsum() - fxi_history['Close'].pct_change().cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d390662",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_ax = (ashr_fxi_difference*100).plot(figsize=(8, 6), \n",
    "                                               title='ASHR Cumulative Returns Subtracted By FXI Cumulative Returns')\n",
    "difference_ax.set_ylabel('Percent %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0073d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ashr_fxi_difference_adjusted = ashr_fxi_difference.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3a63b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_vol = ashr_fxi_difference_adjusted.rolling(60).std()*(252**0.5)\n",
    "rolling_vol_ax = rolling_vol.plot(figsize=(8, 6), \n",
    "                                  title='ASHR / FXI Cumulative Return Difference 60-day Rolling Vol')\n",
    "\n",
    "rolling_vol_ax.set_ylim(0, 1.2)\n",
    "rolling_vol_ax.set_ylabel(\"Vol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb3d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate maximum drawdown\n",
    "roll_max = ashr_fxi_difference_adjusted.rolling(252).max()\n",
    "daily_drawdown = ashr_fxi_difference_adjusted / roll_max - 1.0\n",
    "\n",
    "daily_dd_ax = daily_drawdown.plot(figsize=(8, 6), \n",
    "                                  title='ASHR / FXI Cumulative Return Difference 252-day drawdown')\n",
    "daily_dd_ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a69705",
   "metadata": {},
   "source": [
    "### Return Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d9973",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_upside = ashr_history['Close'].pct_change().cumsum().iloc[-1] - fxi_history['Close'].pct_change().cumsum().iloc[-1]\n",
    "max_upside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.301936 - .18 -.02) / rolling_vol.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5fdf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "evergrande_crisis_date = pd.Timestamp('2021-03-01')\n",
    "ax = (ashr_fxi_difference_adjusted.loc[evergrande_crisis_date:]*100).plot(title='ASHR / FXI Cumulative Return Difference', \n",
    "                                                                    figsize=(8, 6))\n",
    "ax.set_ylim(0, 35)\n",
    "ax.set_ylabel('Percent %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
